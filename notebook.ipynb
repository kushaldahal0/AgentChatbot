{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install langchain langchain_community langchain-huggingface pyPDF2 python-dateutil dateparser faiss-cpu sentence-transformers ipywidgets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from datetime import datetime, timedelta\n",
    "import dateparser\n",
    "from typing import List, Dict\n",
    "from langchain.agents import Tool, AgentExecutor, create_react_agent\n",
    "from langchain.chains import RetrievalQA\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain_core.documents import Document\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEndpoint , HuggingFaceEmbeddings\n",
    "# from langchain_community.embeddings import \n",
    "\n",
    "from huggingface_hub import login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "\n",
    "# Get the Hugging Face token from the .env file\n",
    "huggingface_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "# print(huggingface_token)\n",
    "# login(token=huggingface_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logged in as: jkelver\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import HfApi\n",
    "\n",
    "# Test the token\n",
    "api = HfApi(token=huggingface_token)\n",
    "user_info = api.whoami()\n",
    "print(\"Logged in as:\", user_info[\"name\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize free LLM (Zephyr-7B-beta)\n",
    "llm = HuggingFaceEndpoint(\n",
    "    repo_id=\"HuggingFaceH4/zephyr-7b-beta\",\n",
    "    task=\"text-generation\",\n",
    "    max_new_tokens=512,\n",
    "    temperature=0.5,\n",
    "    huggingfacehub_api_token=huggingface_token, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = HuggingFaceEndpoint(\n",
    "#     repo_id=\"mistralai/Mistral-7B-v0.1\",  # Open-access model\n",
    "#     task=\"text-generation\",\n",
    "#     max_new_tokens=512,\n",
    "#     temperature=0.5,\n",
    "#     huggingfacehub_api_token=huggingface_token,\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = HuggingFaceEndpoint(\n",
    "#     repo_id=\"gpt2\",  # Use a model that works with the API\n",
    "#     task=\"text-generation\",\n",
    "#     max_new_tokens=256,\n",
    "#     temperature=0.3,\n",
    "#     huggingfacehub_api_token=huggingface_token,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize free local embeddings\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Document Processing\n",
    "def load_and_process_documents(pdf_path: str):\n",
    "    # Load PDF using PyPDF2\n",
    "    reader = PdfReader(pdf_path)\n",
    "    pages = []\n",
    "    \n",
    "    # Extract text from each page\n",
    "    for page_num, page in enumerate(reader.pages):\n",
    "        text = page.extract_text()\n",
    "        if text:  # Only add non-empty pages\n",
    "            pages.append(Document(\n",
    "                page_content=text,\n",
    "                metadata={\"source\": pdf_path, \"page\": page_num + 1}\n",
    "            ))\n",
    "    \n",
    "    # Split text into chunks\n",
    "    text_splitter = CharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=200,\n",
    "        separator=\"\\n\"\n",
    "    )\n",
    "    return text_splitter.split_documents(pages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"documents\\charniak.pdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "See discussions, st ats, and author pr ofiles f or this public ation at : https://www .researchgate.ne t/public ation/333899740\n",
      "Charniak, E. An Introduction to Deep Learning\n",
      "Article    in  Perception  · June 2019\n",
      "DOI: 10.1177/0301006619857273\n",
      "CITATIONS\n",
      "10READS\n",
      "1,390\n",
      "1 author:\n",
      "Brian T Sulliv an\n",
      "Univ ersity of Brist ol\n",
      "60 PUBLICA TIONS    1,235  CITATIONS    \n",
      "SEE PROFILE\n",
      "All c ontent f ollo wing this p age was uplo aded b y Brian T Sulliv an on 18 No vember 2022.\n",
      "The user has r equest ed enhanc ement of the do wnlo aded file.\n",
      "----------------------------------------\n",
      "Book Review\n",
      "Charniak, E. An Introduction to Deep Learning . Cambridge, MA: MIT Press, 2019; 192 pp.: ISBN:\n",
      "9780262039512, $35.00 X | £27.00 Hardback.\n",
      "Reviewed by: Brian Sullivan, School of Psychological Sciences, University of Bristol, UK\n",
      "Deep learning with artiﬁcial neural networks has become an incredibly interesting and fast-\n",
      "paced ﬁeld of research that has exploded since the introduction of AlexNet in 2012\n",
      "(Krizhevsky, Sutskever, & Hinton, 2012). Since that time, object recognition networks\n",
      "have matched or exceeded human capacity (He, Zhang, Ren, & Sun, 2015) on image data-bases and have found a wide variety of applications, ranging from speech recognition, to\n",
      "algorithmic generation of faces and landscapes, to reconstruction of visual stimuli from\n",
      "neural recordings. Given the success of these approaches, deep learning’s utility for data\n",
      "analysis, and its potential for modelling aspects of sensory processing and decision making,\n",
      "----------------------------------------\n",
      "neural recordings. Given the success of these approaches, deep learning’s utility for data\n",
      "analysis, and its potential for modelling aspects of sensory processing and decision making,\n",
      "it is essential that researchers in perception become familiar with the variety of techniques\n",
      "that are bundled into the term of deep learning. Deep learning research and applications\n",
      "have been dominated by computer science and engineering, but many cutting-edge tools and\n",
      "algorithms are openly available to be used for data analysis and as a platform for biolog-\n",
      "ically plausible or inspired modelling.\n",
      "Deep learning implies several things: ﬁrst, it is an implementation of an artiﬁcial neural\n",
      "network that has many layers (greater than three and can reach hundreds). Additionally, thenetwork is trained on large datasets (often millions of examples), and lastly the innovations\n",
      "in graphical processing unit (GPU)-based computation allow these complex models\n",
      "----------------------------------------\n",
      "in graphical processing unit (GPU)-based computation allow these complex models\n",
      "(AlexNet for example has /C2462 million parameters) to be optimized, using gradient descent\n",
      "methods and the backpropagation algorithm in a computationally efﬁcient way. Beyond\n",
      "this, deep learning is a catch all term for a large variety of algorithms and approaches that\n",
      "can beneﬁt from the above.\n",
      "Eugene Charniak’s ‘Introduction to Deep Learning’ is a small volume with seven chap-\n",
      "ters brieﬂy covering several important topics concerning the theory behind and implemen-\n",
      "tation of artiﬁcial neural networks. These include simple artiﬁcial neural networks,\n",
      "convolutional networks, recurrent networks, reinforcement learning (RL), and unsupervised\n",
      "learning methods, like autoencoders and generative adversarial networks (GANs).\n",
      "Charniak is a computer scientist specializing in computational linguistics but writes in a\n",
      "relatively casual way that is accessible to readers of other backgrounds. The text is intended\n",
      "----------------------------------------\n",
      "Charniak is a computer scientist specializing in computational linguistics but writes in a\n",
      "relatively casual way that is accessible to readers of other backgrounds. The text is intended\n",
      "as a companion to an introductory course he teaches, and without his lectures, not all\n",
      "aspects are as comprehensive as other texts available as I will outline below. Readersshould be familiar (but not necessarily an expert) with Python, linear algebra, multivariate\n",
      "calculus, probability theory, and statistics. The book gives several Python languagePerception\n",
      "2019, Vol. 48(8) 759–761\n",
      "!The Author(s) 2019\n",
      "Article reuse guidelines:\n",
      "sagepub.com/journals-permissions\n",
      "DOI: 10.1177/0301006619857273\n",
      "journals.sagepub.com/home/pec\n",
      "----------------------------------------\n",
      "programming examples, using the NumPy and most importantly TensorFlow libraries\n",
      "(https://www.tensorﬂow.org/). Each chapter spends about 20 pages exploring a particulartopic, covering the mathematical basis, some code examples and providing follow-up read-ing suggestions and end of chapter exercises. For instance, the ﬁrst chapter discusses thegeneral theory behind artiﬁcial neural networks, their grounding in linear algebra and how\n",
      "one could optimize one using the backpropagation algorithm. The following chapter intro-\n",
      "duces TensorFlow and the basics of how one sets up a computational architecture (inputs,network layers, loss function, optimization function, etc.) that can then be run on a data set.Relatively quickly you’ll be up and running examples of single- and double-layer and con-volutional networks.\n",
      "Later chapters cover more complex topics and Charniak, at times, varies in elucidation.\n",
      "----------------------------------------\n",
      "Later chapters cover more complex topics and Charniak, at times, varies in elucidation.\n",
      "He is especially good at describing in plain language some of the details for how his codeexamples work, and for providing useful distillations of reinforcement learning, autoen-coders and GANs, but his writing can be less helpful in other areas. In particular, thechapters on recurrent networks and sequence-to-sequence learning involve many referencesto data sets and results that the reader doesn’t have immediate access to (unlike early\n",
      "chapters with more explicit code using the MNIST handwritten digit data set). This can\n",
      "----------------------------------------\n",
      "chapters with more explicit code using the MNIST handwritten digit data set). This can\n",
      "make things hard to follow along, unless the reader is sufﬁciently advanced to know how toimplement the networks and ﬁnd the correct data set themselves online. Generally, Charniakmakes a good effort to be clear on each topic presented and how the code examples work,but without further explanation some elements may be cryptic. Therefore, I would highlyrecommend readers to consult the TensorFlow online documentation and tutorials. Similarattention to online documentation and tutorials are needed in the reinforcement learning\n",
      "chapter to follow the examples Charniak provides using Open.AI Gym (https://gym.openai.\n",
      "----------------------------------------\n",
      "chapter to follow the examples Charniak provides using Open.AI Gym (https://gym.openai.\n",
      "com/), a library supporting environments commonly used for training RL systems. At thetime of this review, the book does not feature an online component. I have therefore createda GitHub repository with direct implementations of nearly all the code examples, locatedhere: https://github.com/VisionResearchBlog/Introduction-to-deep-learning-code-examples\n",
      "Charniak’s book arrives at a time with many avenues for learning or teaching about deep\n",
      "learning. One of the most amazing aspects of the current deep learning revolution is thatthere are many open source online tutorials and codebases to learn from. Additionally, thereare several books (online or print, several free and all under $80) that cover similar topics asCharniak’s book.\n",
      "1–5Despite such stiff competition, Charniak’s book is affordable and\n",
      "approachable for beginners; it has useful code examples and is a quick read. He gives\n",
      "----------------------------------------\n",
      "1–5Despite such stiff competition, Charniak’s book is affordable and\n",
      "approachable for beginners; it has useful code examples and is a quick read. He gives\n",
      "many references for extra reading, if the reader wants a more thorough understanding.The book would work best, however, as a companion to a course where an instructorcould provide more in-depth treatments of the mathematics, and more code instruction,and supplemented with primary texts and readings like the sources above.\n",
      "Given the wide variety of resources for learning about the ﬁeld of deep learning, I would\n",
      "highly encourage Perception readers to explore all options available to ﬁnd what suits their\n",
      "needs, as there are texts for beginner to advanced, several with large codebases and tutorialsto be explored.\n",
      "Declaration of Conflicting Interests\n",
      "The author(s) declared no potential conﬂicts of interest with respect to the research, authorship, and/or\n",
      "publication of this article.760 Perception 48(8)\n",
      "----------------------------------------\n",
      "Funding\n",
      "The author(s) received no ﬁnancial support for the research, authorship, and/or publication of\n",
      "this article.\n",
      "Notes\n",
      "1. Goodfellow, I., Bengio, Y., & Courville, A. (2016). Deep learning . Cambridge, MA: MIT Press.\n",
      "Retrieved from http://www.deeplearningbook.org\n",
      "2. Nielsen, M. A. (2015). Neural networks and deep learning (Vol. 25). San Francisco, CA:\n",
      "Determination Press. Retrieved from http://neuralnetworksanddeeplearning.com/\n",
      "3. Rashid, T. (2016). Make your own neural network . Scotts Valley, CA: CreateSpace Independent\n",
      "Publishing Platform. Retrieved from https://github.com/makeyourownneuralnetwork\n",
      "4. Taylor, M. (2017). Make your own neural network: An in-depth visual introduction for beginners .\n",
      "Independently Published. Retrieved from https://dl.acm.org/citation.cfm?id ¼3181149\n",
      "5. Zhang, L., & Li, S. (2019). Dive into deep learning release . Retrieved from https://d2l.ai/\n",
      "References\n",
      "He, K., Zhang, X., Ren, S., & Sun, J. (2015). Delving deep into rectiﬁers: Surpassing human-level\n",
      "----------------------------------------\n",
      "References\n",
      "He, K., Zhang, X., Ren, S., & Sun, J. (2015). Delving deep into rectiﬁers: Surpassing human-level\n",
      "performance on ImageNet classiﬁcation. In Proceedings of the IEEE international conference on\n",
      "computer vision , Santiago, Chile, (pp. 1026–1034). ICCV.\n",
      "Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). ImageNet classiﬁcation with deep convolutional\n",
      "neural networks. In Advances in neural information processing systems , Lake Tahoe, UT, USA, (pp.\n",
      "1097–1105). NIPS.Book Review 761\n",
      "View publication stats\n"
     ]
    }
   ],
   "source": [
    "docsT = load_and_process_documents(file_path)\n",
    "for doc in docsT:\n",
    "  print(\"-\"*40)\n",
    "  print(doc.page_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Vector Store\n",
    "try:\n",
    "    docs = load_and_process_documents(file_path)\n",
    "    vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "    retriever = vectorstore.as_retriever()\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing vector store: {e}\")\n",
    "    exit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation Functions\n",
    "def validate_email(email: str) -> bool:\n",
    "    pattern = r\"^[a-zA-Z0-9_.+-]+@[a-zA-Z0-9-]+\\.[a-zA-Z0-9-.]+$\"\n",
    "    return re.match(pattern, email) is not None\n",
    "\n",
    "def validate_phone(phone: str) -> bool:\n",
    "    pattern = r\"^\\+?[1-9]\\d{1,14}$\"\n",
    "    return re.match(pattern, phone) is not None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import dateparser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"error_can't compare offset-naive and offset-aware datetimes\""
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def parse_date(text: str) -> str:\n",
    "    \"\"\"Enhanced date parsing with validation and fallback.\"\"\"\n",
    "    try:\n",
    "        # Parse with context-aware settings\n",
    "        date = dateparser.parse(\n",
    "            text,\n",
    "            settings={\n",
    "                'PREFER_DATES_FROM': 'future',\n",
    "                'RELATIVE_BASE': datetime.now(),\n",
    "                'RETURN_AS_TIMEZONE_AWARE': True\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # If dateparser fails to parse, try to manually handle relative weekdays or explicit dates.\n",
    "        if not date:\n",
    "            # Manually handle explicit date format like \"March 25\"\n",
    "            try:\n",
    "                # Try parsing explicit dates like \"March 25\"\n",
    "                date = datetime.strptime(text, \"%B %d\")\n",
    "                \n",
    "                # If the date has already passed this year, update to the next year\n",
    "                if date < datetime.now():\n",
    "                    date = date.replace(year=datetime.now().year + 1)\n",
    "            \n",
    "            except ValueError:\n",
    "                pass  # Continue if not an explicit date\n",
    "\n",
    "            # If still not parsed, handle relative weekdays like \"next Monday\"\n",
    "            if not date:\n",
    "                # Mapping of weekday names to their respective weekday number\n",
    "                days_of_week = {\n",
    "                    'monday': 0,\n",
    "                    'tuesday': 1,\n",
    "                    'wednesday': 2,\n",
    "                    'thursday': 3,\n",
    "                    'friday': 4,\n",
    "                    'saturday': 5,\n",
    "                    'sunday': 6\n",
    "                }\n",
    "                \n",
    "                # Check for the weekday in the text and calculate the next occurrence\n",
    "                for day_str, weekday in days_of_week.items():\n",
    "                    if day_str in text.lower():\n",
    "                        days_ahead = (weekday - datetime.now().weekday()) + 7\n",
    "                        if days_ahead <= 0:  # If the specified day is today, move to the next one\n",
    "                            days_ahead += 7\n",
    "                        date = datetime.now() + timedelta(days=days_ahead)\n",
    "                        break\n",
    "\n",
    "        if not date:\n",
    "            return None\n",
    "\n",
    "        # Validate future date (minimum 24 hours ahead)\n",
    "        if date < datetime.now() + timedelta(hours=24):\n",
    "            return \"date_too_soon\"\n",
    "        \n",
    "        # Return the date in the desired format\n",
    "        return date.strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"error_{str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2025-01-31'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_date(\"next friday\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def book_appointment_handler(query: str) -> str:\n",
    "    \"\"\"Enhanced appointment booking tool\"\"\"\n",
    "    parsed = parse_date(query)\n",
    "    \n",
    "    if parsed is None:\n",
    "        return \"DATE_ERROR: Couldn't recognize the date. Please specify like:\\n- 'Next Tuesday at 2PM'\\n- 'March 25th'\\n- 'Tomorrow morning'\"\n",
    "    \n",
    "    if isinstance(parsed, str) and parsed.startswith(\"error\"):\n",
    "        return f\"DATE_ERROR: Invalid date format - {parsed[6:]}\"\n",
    "    \n",
    "    if parsed == \"date_too_soon\":\n",
    "        return \"DATE_ERROR: Please choose a date at least 24 hours in advance\"\n",
    "    \n",
    "    return f\"SUGGESTION: {parsed}\\nCONFIRM: Does this work for you? (yes/no)\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"DATE_ERROR: Invalid date format - can't compare offset-naive and offset-aware datetimes\""
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Conversation State\n",
    "class FormState:\n",
    "    def __init__(self):\n",
    "        self.active = False\n",
    "        self.current_form = None\n",
    "        self.collected_data = {}\n",
    "        self.required_fields = []\n",
    "\n",
    "form_state = FormState()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tools\n",
    "tools = [\n",
    "    Tool(\n",
    "        name=\"DocumentQA\",\n",
    "        func=lambda q: RetrievalQA.from_chain_type(llm=llm, retriever=retriever).invoke(q),\n",
    "        description=\"Answers questions from PDF documents\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"ScheduleCall\",\n",
    "        func=lambda _: \"Please provide your name, phone, and email in this format: [Name] [Phone] [Email]\",\n",
    "        description=\"Initiates call scheduling process\"\n",
    "    ),\n",
    "    Tool(\n",
    "        name=\"BookAppointment\",\n",
    "        func=book_appointment_handler,\n",
    "        description=\"Handles appointment booking. Input examples: 'next Monday', 'March 25th at 2PM', 'tomorrow morning'\"\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the prompt template with all required variables\n",
    "prompt_template = \"\"\"You are an intelligent assistant designed to answer user questions based on the provided document. Follow these rules strictly:\n",
    "\n",
    "1. **Document-Based Answers**:\n",
    "   - If the question is about the document, provide only relevant information from the document.\n",
    "   - Do not make up answers or include external knowledge.\n",
    "\n",
    "2. **Tool Usage**:\n",
    "   - You have access to the following tools: {tools}.\n",
    "   - Use the tools only when necessary to answer the question.\n",
    "   - Always follow this format:\n",
    "     - Thought: Think about what to do next.\n",
    "     - Action: Choose the appropriate tool from [{tool_names}].\n",
    "     - Action Input: Provide the input for the tool.\n",
    "     - Observation: Record the result of the tool's action.\n",
    "\n",
    "3. **Final Answer**:\n",
    "   - After gathering all necessary information, provide a concise and accurate final answer.\n",
    "   - Do not repeat the question or include unnecessary details.\n",
    "\n",
    "4. **Efficiency**:\n",
    "   - Use the minimum number of steps to answer the question.\n",
    "   - Avoid unnecessary tool usage or repetitive actions.\n",
    "\n",
    "5. **Format**:\n",
    "   - Always follow this structure:\n",
    "     - Question: The input question.\n",
    "     - Thought: Your reasoning.\n",
    "     - Action: The tool to use (if needed).\n",
    "     - Action Input: The input for the tool (if needed).\n",
    "     - Observation: The result of the tool (if used).\n",
    "     - Final Answer: The final response to the question.\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "# Create the PromptTemplate\n",
    "prompt = PromptTemplate.from_template(prompt_template)\n",
    "\n",
    "# Create the ReAct agent\n",
    "agent = create_react_agent(llm, tools, prompt)\n",
    "# Create the AgentExecutor\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True, handle_parsing_errors=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import widgets, Layout, Output\n",
    "from IPython.display import display, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot():\n",
    "    print(\"Welcome to the Free Document Chatbot!\")\n",
    "    print(\"You can:\")\n",
    "    print(\"1. Ask questions about the PDF document\")\n",
    "    print(\"2. Say 'schedule call' to book a meeting\")\n",
    "    print(\"3. Say 'book appointment' to schedule an appointment\")\n",
    "    # Create widgets for interaction\n",
    "    input_box = widgets.Text(placeholder=\"Type your message here...\", layout=Layout(width=\"80%\"))\n",
    "    send_button = widgets.Button(description=\"Send\")\n",
    "    output_area = Output()\n",
    "\n",
    "    # Display widgets\n",
    "    display(widgets.HBox([input_box, send_button]), output_area)\n",
    "\n",
    "    def handle_submit(_):\n",
    "        user_input = input_box.value.strip()\n",
    "        input_box.value = \"\"  # Clear the input box\n",
    "\n",
    "        with output_area:\n",
    "            if not user_input:\n",
    "                return\n",
    "\n",
    "            # Handle form state\n",
    "            if form_state.active:\n",
    "                # Validate input based on current field\n",
    "                current_field = form_state.required_fields[0]\n",
    "                \n",
    "                if current_field == \"email\" and not validate_email(user_input):\n",
    "                    print(\"Agent: Invalid email format. Please try again.\")\n",
    "                    return\n",
    "                \n",
    "                if current_field == \"phone\" and not validate_phone(user_input):\n",
    "                    print(\"Agent: Invalid phone format. Please use international format (+XX...)\")\n",
    "                    return\n",
    "                \n",
    "                form_state.collected_data[current_field] = user_input\n",
    "                form_state.required_fields.pop(0)\n",
    "                \n",
    "                if not form_state.required_fields:\n",
    "                    print(\"Agent: Thank you! We'll contact you soon.\")\n",
    "                    print(f\"Collected info: {form_state.collected_data}\")\n",
    "                    form_state.active = False\n",
    "                else:\n",
    "                    print(f\"Agent: Please provide your {form_state.required_fields[0]}:\")\n",
    "                return\n",
    "\n",
    "            # Handle special commands\n",
    "            if \"schedule call\" in user_input.lower():\n",
    "                form_state.active = True\n",
    "                form_state.required_fields = [\"name\", \"phone\", \"email\"]\n",
    "                form_state.collected_data = {}\n",
    "                print(\"Agent: Please provide your name:\")\n",
    "                return\n",
    "\n",
    "            #book appointment \n",
    "            if \"book appointment\" in user_input.lower():\n",
    "                response = agent_executor.invoke({\"input\": user_input})\n",
    "                output = response['output']\n",
    "                \n",
    "                if \"SUGGESTION:\" in output:\n",
    "                    print(f\"Agent: {output}\")\n",
    "                    confirmation = input(\"You: \").lower()\n",
    "                    if confirmation == \"yes\":\n",
    "                        print(\"Agent: Appointment booked successfully!\")\n",
    "                        # Store the appointment in form_state.collected_data\n",
    "                    else:\n",
    "                        print(\"Agent: Let's try another date. Please specify:\")\n",
    "                elif \"DATE_ERROR:\" in output:\n",
    "                    print(f\"Agent: {output[10:]}\")\n",
    "                else:\n",
    "                    print(f\"Agent: {output}\")\n",
    "                    # continue\n",
    "            # Handle document questions\n",
    "            response = agent_executor.invoke({\"input\": user_input})\n",
    "            print(f\"Agent: {response['output']}\")\n",
    "\n",
    "    # Attach the handler to the button\n",
    "    send_button.on_click(handle_submit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Free Document Chatbot!\n",
      "You can:\n",
      "1. Ask questions about the PDF document\n",
      "2. Say 'schedule call' to book a meeting\n",
      "3. Say 'book appointment' to schedule an appointment\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "986ef2f4b3ae477e9e9231c6dbf2b468",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(Text(value='', layout=Layout(width='80%'), placeholder='Type your message here...'), Button(des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "53cec54a7bbc43ba910df969d4f111bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "chatbot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def main():\n",
    "#     print(\"Welcome to the Free Document Chatbot!\")\n",
    "#     print(\"You can:\")\n",
    "#     print(\"1. Ask questions about the PDF document\")\n",
    "#     print(\"2. Say 'schedule call' to book a meeting\")\n",
    "#     print(\"3. Say 'book appointment' to schedule an appointment\")\n",
    "    \n",
    "#     while True:\n",
    "#         try:\n",
    "#             user_input = input(\"\\nYou: \").strip()\n",
    "            \n",
    "#             if not user_input:\n",
    "#                 continue\n",
    "\n",
    "#             # Handle form state\n",
    "#             if form_state.active:\n",
    "#                 # Validate input based on current field\n",
    "#                 current_field = form_state.required_fields[0]\n",
    "                \n",
    "#                 if current_field == \"email\" and not validate_email(user_input):\n",
    "#                     print(\"Agent: Invalid email format. Please try again.\")\n",
    "#                     continue\n",
    "                \n",
    "#                 if current_field == \"phone\" and not validate_phone(user_input):\n",
    "#                     print(\"Agent: Invalid phone format. Please use international format (+XX...)\")\n",
    "#                     continue\n",
    "                \n",
    "#                 form_state.collected_data[current_field] = user_input\n",
    "#                 form_state.required_fields.pop(0)\n",
    "                \n",
    "#                 if not form_state.required_fields:\n",
    "#                     print(\"Agent: Thank you! We'll contact you soon.\")\n",
    "#                     print(f\"Collected info: {form_state.collected_data}\")\n",
    "#                     form_state.active = False\n",
    "#                 else:\n",
    "#                     print(f\"Agent: Please provide your {form_state.required_fields[0]}:\")\n",
    "#                 continue\n",
    "\n",
    "#             # Handle special commands\n",
    "#             if \"schedule call\" in user_input.lower():\n",
    "#                 form_state.active = True\n",
    "#                 form_state.required_fields = [\"name\", \"phone\", \"email\"]\n",
    "#                 form_state.collected_data = {}\n",
    "#                 print(\"Agent: Please provide your name:\")\n",
    "#                 continue\n",
    "\n",
    "#             #book appointment \n",
    "#             if \"book appointment\" in user_input.lower():\n",
    "#                 response = agent_executor.invoke({\"input\": user_input})\n",
    "#                 output = response['output']\n",
    "                \n",
    "#                 if \"SUGGESTION:\" in output:\n",
    "#                     print(f\"Agent: {output}\")\n",
    "#                     confirmation = input(\"You: \").lower()\n",
    "#                     if confirmation == \"yes\":\n",
    "#                         print(\"Agent: Appointment booked successfully!\")\n",
    "#                         # Store the appointment in form_state.collected_data\n",
    "#                     else:\n",
    "#                         print(\"Agent: Let's try another date. Please specify:\")\n",
    "#                 elif \"DATE_ERROR:\" in output:\n",
    "#                     print(f\"Agent: {output[10:]}\")\n",
    "#                 else:\n",
    "#                     print(f\"Agent: {output}\")\n",
    "#                 continue\n",
    "\n",
    "#             # Handle document questions\n",
    "#             response = agent_executor.invoke({\"input\": user_input})\n",
    "#             print(f\"Agent: {response['output']}\")\n",
    "\n",
    "#         except KeyboardInterrupt:\n",
    "#             print(\"\\nGoodbye!\")\n",
    "#             break\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error: {str(e)}\")\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chatbot()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
